# Connect Kafka to AWS CodePipeline

<div class="connect-images cards blog-grid-card" markdown>
<div>
<img src="../images/kafka_logo.png" width="40px" />
</div>
<div>
<img src="../images/arrow.svg" width="40px" />
</div>
<div>
<img src="./images/aws-codepipeline_1.jpg" />
</div>
</div>

Quix helps you integrate Apache Kafka with AWS CodePipeline using pure Python.

Transform and pre-process data, with the new alternative to Confluent Kafka Connect, before loading it into a specific format, simplifying data lake house architecture, reducing storage and ownership costs and enabling data teams to achieve success for your business.

## AWS CodePipeline

AWS CodePipeline is a continuous integration and continuous delivery service provided by Amazon Web Services. This tool allows developers to automate the process of releasing code changes for their applications. With CodePipeline, users can define their workflow for deploying code from source control repositories such as GitHub or AWS CodeCommit. This service enables teams to quickly and efficiently deliver software updates, test and validate changes, and deploy them to production with ease. AWS CodePipeline streamlines the development process and helps teams to deliver high-quality software at a faster pace.

## Integrations

<div class="grid cards" markdown>

- __Find out how we can help you integrate!__

    <a class="md-button md-button--primary" href="https://quix.io/book-a-demo" target="_blank" style="margin:.5rem;">Book a demo</a>

</div>


Quix is a great fit for integrating with AWS CodePipeline due to its ability to enable data engineers to pre-process and transform data from various sources before loading it into a specific data format. This simplifies lakehouse architecture with customizable connectors for different destinations. Additionally, Quix Streams, an open-source Python library, facilitates the transformation of data using streaming DataFrames, supporting operations like aggregation, filtering, and merging during the transformation process.

Furthermore, Quix ensures efficient handling of data from source to destination with no throughput limits, automatic backpressure management, and checkpointing. It also supports sinking transformed data to cloud storage in a specific format, ensuring seamless integration and storage efficiency at the destination. This not only streamlines the data integration process but also helps lower the total cost of ownership compared to other alternatives.

In conclusion, Quix provides a robust and cost-effective solution for managing data integration from source through transformation to destination, making it an ideal tool to integrate with AWS CodePipeline.

